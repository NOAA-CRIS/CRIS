{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aace3466",
   "metadata": {},
   "source": [
    "Name: 01_observed_climatology_data_processing<br>\n",
    "Description: This notebook contains the core code used for proessing Livneh and nClimGrid historic observed climatology data into standand cliamte indices. The Livneh and nClimGrid data files are netCDF format and contine daily tmax, tmin, and prcp. The Python xclim package was used for processing the input data into the indices. xclim Official Documentation https://xclim.readthedocs.io/en/stable/<br>\n",
    "Date: August 2024<br>\n",
    "Requirements: Python 3.11.10, xclim 0.47.0, xarray 2023.6.0<br>\n",
    "Author: Mark Gilbert, Principle GIS Engineer, ArcGIS Living Atlas of the World, Esri (mgilbert@esri.com)<br>\n",
    "<Br>\n",
    "Livneh, B., T. J. Bohn, D. W. Pierce, F. Munoz-Arriola, B. Nijssen, R. Vose, D. R. Cayan, and L. Brekke, 2015: A spatially comprehensive, hydrometeorological data set for Mexico, the U.S., and Southern Canada 1950–2013. Scientific Data, 2, https://doi.org/10.1038/sdata.2015.42.<br>\n",
    "<br>\n",
    "Durre, I., M. F. Squires, R. S. Vose, A. Arguez, W. S. Gross, J. R. Rennie, and C. J. Schreck, 2022b: NOAA's nClimGrid-Daily Version 1 – Daily gridded temperature and precipitation for the Contiguous United States since 1951. NOAA National Centers for Environmental Information, since 6 May 2022, https://doi.org/10.25921/c4gt-r169\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55921884-52ed-4764-963b-e0e8263dffdf",
   "metadata": {},
   "source": [
    "### Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca4b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from distributed import Client\n",
    "\n",
    "import xarray as xr\n",
    "import xclim\n",
    "from xclim.core import units\n",
    "\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51720969-b495-4259-a758-72127911c190",
   "metadata": {},
   "source": [
    "### Dask Parallel Processing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe2a8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Depending on your workstation specifications, you may need to adjust these values.\n",
    "# On a single machine, n_workers=1 is usually better.\n",
    "# \n",
    "# client = Client(n_workers=1, threads_per_worker=8, memory_limit=\"12GB\")\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a36e72",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the name of the dataset to process.\n",
    "# TODO: Add your path to the log file.\n",
    "#\n",
    "LOG_FILE_PATH = r\"[add_path]\\Log_Output\"\n",
    "\n",
    "# TODO: Uncomment the dataset you wish to work with\n",
    "#\n",
    "# IN_DATASET = \"Livneh\"\n",
    "# IN_PATH = r\"C:\\noaa_data\\Livneh_Source\\*.nc\"\n",
    "# OUT_PATH = r\"C:\\noaa_data\\Livneh_Thresholds_netCDF\"\n",
    "\n",
    "IN_DATASET = \"nClimGrid\"\n",
    "IN_PATH = r\"Z:\\nClimGrid_Source\\*.nc\" # \"C:\\noaa_data\\nClimGrid_Source\\*.nc\"\n",
    "OUT_PATH = r\"Z:\\nClimGrid_Thresholds_netCDF\" # \"C:\\noaa_data\\nClimGrid_Thresholds_netCDF\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9e806",
   "metadata": {},
   "source": [
    "### Setup Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2b931ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging to file and stdout\n",
    "#\n",
    "file_time = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "log_file_name = \"Output_Log_xclim_Processing_\" + file_time + \".log\"\n",
    "LOG_FILE = os.path.join(LOG_FILE_PATH, log_file_name)\n",
    "\n",
    "logging.basicConfig(level = logging.INFO,\n",
    "                    format=\"%(asctime)s:%(levelname)s: %(message)s\",\n",
    "                    handlers=[\n",
    "                       logging.FileHandler(filename=LOG_FILE),\n",
    "                       logging.StreamHandler(sys.stdout)\n",
    "                   ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b82dd14-03f8-495b-9d31-17d11245e38d",
   "metadata": {},
   "source": [
    "### Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ba4407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-20 16:05:12,730:INFO: Beginning data processing...\n",
      "2024-08-20 16:09:25,447:INFO: nClimGrid loaded from Z:\\nClimGrid_Source\\*.nc\n"
     ]
    }
   ],
   "source": [
    "# Create dataset from multiple files\n",
    "#\n",
    "logging.info(\"Beginning data processing...\")\n",
    "if IN_DATASET == \"Livneh\":\n",
    "    # %time ds_livneh_source = xr.open_mfdataset(r\"G:\\Livneh\\*.nc\", drop_variables=[\"wind\"], parallel=True)\n",
    "    ds_source = xr.open_mfdataset(IN_PATH, drop_variables=[\"wind\"])\n",
    "    \n",
    "elif IN_DATASET == \"nClimGrid\":\n",
    "    # %time ds_nclimgrid_source = xr.open_mfdataset(r\"G:\\nClimGrid\\*.nc\", parallel=True)\n",
    "    ds_source = xr.open_mfdataset(IN_PATH)\n",
    "else:\n",
    "    logging.info(f\"{IN_DATASET} does not exist. Ending.\")\n",
    "    sys.exit()\n",
    "    \n",
    "logging.info(f\"{IN_DATASET} loaded from {IN_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c40a832",
   "metadata": {},
   "source": [
    "Do some cleanup of poorly documented source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f58763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a deep copy of the source dataset\n",
    "#\n",
    "ds_working = ds_source.copy(deep=True)\n",
    "\n",
    "# Get the begin and end years for the output file names\n",
    "#\n",
    "begin_year = ds_working.time.dt.year[0].values.item()\n",
    "end_year =  ds_working.time.dt.year[-1].values.item()\n",
    "\n",
    "logging.info(f\"Doing data cleanup on {IN_DATASET}...\")\n",
    "if IN_DATASET == \"Livneh\":\n",
    "    # Update the variables names for Livneh. They do not follow all the CF Conventions.\n",
    "    #\n",
    "    ds_working = ds_working.rename(Prec=\"prcp\")\n",
    "    ds_working = ds_working.rename(Tmax=\"tmax\")\n",
    "    ds_working = ds_working.rename(Tmin=\"tmin\")\n",
    "\n",
    "    # Add a standard_name attribute to Livneh.tmax/tmin. Otherwsie you will get a warning when sending these \n",
    "    # variables to the indicators.atmos.tg function.\n",
    "    #\n",
    "    ds_working[\"tmax\"] = ds_working.tmax.assign_attrs(standard_name=\"air_temperature\")\n",
    "    ds_working[\"tmin\"] = ds_working.tmin.assign_attrs(standard_name=\"air_temperature\")\n",
    "    \n",
    "    # Add cell_methods attributes to Livneh/nClimGrid tmax/tmin to avoid warnings when calculating annual averages.\n",
    "    #\n",
    "    ds_working[\"tmax\"] = ds_working.tmax.assign_attrs(cell_methods='time: maximum within days')\n",
    "    ds_working[\"tmin\"] = ds_working.tmin.assign_attrs(cell_methods='time: minimum within days')\n",
    "    \n",
    "    # Calculate tavg for Livneh. The source does not include it. Needed for CDD/HDD.\n",
    "    # tavg gets standard_name and cell_methods from the Indicator function\n",
    "    #\n",
    "    logging.info(f\"Calculating tavg for {IN_DATASET}...\")\n",
    "    ds_working[\"tavg\"] = xclim.indicators.atmos.tg(tasmin=ds_working.tmin, tasmax=ds_working.tmax)\n",
    "\n",
    "elif IN_DATASET == 'nClimGrid':\n",
    "    # Add a cell_methods attribute to nClimGrid tavg to avoid a CF warning when calculation CDD/HDD\n",
    "    #\n",
    "    ds_working[\"tavg\"] = ds_working.tavg.assign_attrs(cell_methods='time: mean within days')\n",
    "    ds_working[\"tmax\"] = ds_working.tmax.assign_attrs(cell_methods='time: maximum within days')\n",
    "    ds_working[\"tmin\"] = ds_working.tmin.assign_attrs(cell_methods='time: minimum within days')\n",
    "\n",
    "# Both datasets need this attribute to avoid warnings\n",
    "# A CF Convention for standard_name for precip is \"lwe_thickness_of_precipitation_amount\".\n",
    "# Source data had no cell_methods. \n",
    "#\n",
    "ds_working[\"prcp\"] = ds_working.prcp.assign_attrs(standard_name=\"lwe_thickness_of_precipitation_amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356af53",
   "metadata": {},
   "source": [
    "### Calculate Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Starting threshold processing...\")\n",
    "\n",
    "out_file_list = []\n",
    "file_suffix = str(begin_year) + \"_\" + str(end_year) + \".nc\"\n",
    "\n",
    "# Cooling Degree Days in degF-days\n",
    "# Threshold set at 65 degF per NOAA and Year End as the frequency, e.g. YYYY-12-31\n",
    "# tavg in nClimGrid does not have a cell_methods attribute but Livneh does. Livneh tavg gets the attribute added\n",
    "# by the xclim atmos.tg function.\n",
    "#\n",
    "logging.info(f\"Calculating cooling/heating degree days for {IN_DATASET}\")\n",
    "cooling_degree_days = xclim.indicators.atmos.cooling_degree_days(tas=ds_working.tavg, thresh='65.0 degF', freq='YE')\n",
    "cooling_degree_days_F_days = units.convert_units_to(cooling_degree_days, \"day fahrenheit\")\n",
    "out_file_list.append((cooling_degree_days_F_days, f\"{IN_DATASET}_cdd_{file_suffix}\"))\n",
    "\n",
    "# Heating Degree Days in degF-days\n",
    "#\n",
    "heating_degree_days = xclim.indicators.atmos.heating_degree_days(tas=ds_working.tavg, thresh='65.0 degF', freq='YE')\n",
    "heating_degree_days_F_days = units.convert_units_to(heating_degree_days, \"day fahrenheit\")\n",
    "out_file_list.append((heating_degree_days_F_days, f\"{IN_DATASET}_hdd_{file_suffix}\"))\n",
    "\n",
    "# Annual Average Temperatures in degF (tmax, tmin, tavg)\n",
    "# TODO: Add cell_methods attribute updates to avoid these warnings\n",
    "#\n",
    "logging.info(f\"Calculating annual average temperatures for {IN_DATASET}\")\n",
    "tmax_annual_mean = xclim.indicators.atmos.tx_mean(tasmax=ds_working.tmax, freq=\"YE\")\n",
    "tmin_annual_mean = xclim.indicators.atmos.tn_mean(tasmin=ds_working.tmin, freq=\"YE\")\n",
    "tavg_annual_mean = xclim.indicators.atmos.tg_mean(tas=ds_working.tavg, freq=\"YE\")\n",
    "\n",
    "tmax_annual_mean_F = units.convert_units_to(tmax_annual_mean, \"degF\")\n",
    "tmin_annual_mean_F = units.convert_units_to(tmin_annual_mean, \"degF\")\n",
    "tavg_annual_mean_F = units.convert_units_to(tavg_annual_mean, \"degF\")\n",
    "\n",
    "out_file_list.append((tmax_annual_mean_F, f\"{IN_DATASET}_tmax_{file_suffix}\"))\n",
    "out_file_list.append((tmin_annual_mean_F, f\"{IN_DATASET}_tmin_{file_suffix}\"))\n",
    "out_file_list.append((tavg_annual_mean_F, f\"{IN_DATASET}_tavg_{file_suffix}\"))\n",
    "\n",
    "\n",
    "# Resample Precipitation to Monthly and Annual Sums in Inches (pr_annual, pr_monthly)\n",
    "#\n",
    "logging.info(f\"Calculating pr_annual for {IN_DATASET}\")\n",
    "pr_annual = ds_working.prcp.resample(time=\"YE\").sum()\n",
    "\n",
    "logging.info(f\"Calculating pr_monthly for {IN_DATASET}\")\n",
    "pr_monthly = ds_working.prcp.resample(time=\"ME\").sum()\n",
    "\n",
    "pr_annual_in = units.convert_units_to(pr_annual, \"in\")\n",
    "pr_monthly_in = units.convert_units_to(pr_monthly, \"in\")\n",
    "out_file_list.append((pr_annual_in, f\"{IN_DATASET}_pr-annual_{file_suffix}\"))\n",
    "out_file_list.append((pr_monthly_in, f\"{IN_DATASET}_pr-monthly_{file_suffix}\"))\n",
    "\n",
    "# precipitation max over a window\n",
    "#\n",
    "# max_n_day_precipitation_amount requires varialbe in precipitation flux\n",
    "# Source was originally in mm (thickness).\n",
    "#\n",
    "ds_working[\"prcp\"] = units.convert_units_to(ds_working.prcp, \"kg m-2 s-1\")\n",
    "# The units conversion doesn't seem to add a cell_methods attribute.\n",
    "# Setting this to avoid a warning\n",
    "#\n",
    "ds_working[\"prcp\"] = ds_working.prcp.assign_attrs(cell_methods='time: mean within days')\n",
    "\n",
    "logging.info(f\"Calculating prmax1day for {IN_DATASET}...\")\n",
    "prmax1day = xclim.indicators.atmos.max_n_day_precipitation_amount(pr=ds_working.prcp, window=1, freq='YE')\n",
    "prmax1day_in = units.convert_units_to(prmax1day, \"in\")\n",
    "out_file_list.append((prmax1day_in, f\"{IN_DATASET}_prmax1day_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating prmax5day for {IN_DATASET}...\")\n",
    "prmax5day = xclim.indicators.atmos.max_n_day_precipitation_amount(pr=ds_working.prcp, window=5, freq='YE')\n",
    "prmax5day_in = units.convert_units_to(prmax5day, \"in\")\n",
    "out_file_list.append((prmax5day_in, f\"{IN_DATASET}_prmax5day_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating prmax10day for {IN_DATASET}...\")\n",
    "prmax10day = xclim.indicators.atmos.max_n_day_precipitation_amount(pr=ds_working.prcp, window=10, freq='YE')\n",
    "prmax10day_in = units.convert_units_to(prmax10day, \"in\")\n",
    "out_file_list.append((prmax10day_in, f\"{IN_DATASET}_prmax10day_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating prmax20day for {IN_DATASET}...\")\n",
    "prmax20day = xclim.indicators.atmos.max_n_day_precipitation_amount(pr=ds_working.prcp, window=20, freq='YE')\n",
    "prmax20day_in = units.convert_units_to(prmax20day, \"in\")\n",
    "out_file_list.append((prmax20day_in, f\"{IN_DATASET}_prmax20day_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating prmax30day for {IN_DATASET}...\")\n",
    "prmax30day = xclim.indicators.atmos.max_n_day_precipitation_amount(pr=ds_working.prcp, window=30, freq='YE')\n",
    "prmax30day_in = units.convert_units_to(prmax30day, \"in\")\n",
    "out_file_list.append((prmax30day_in, f\"{IN_DATASET}_prmax30day_{file_suffix}\"))\n",
    "\n",
    "# psmax seasonal\n",
    "#\n",
    "logging.info(f\"Calculating prmax_seasonal for {IN_DATASET}...\")\n",
    "prmax_seasonal = ds_working.prcp.resample(time=\"QS-DEC\").max(dim=\"time\")\n",
    "prmax_seasonal_in =  units.convert_units_to(prmax_seasonal, \"in\")\n",
    "out_file_list.append((prmax_seasonal_in, f\"{IN_DATASET}_prmax-seasonal_{file_suffix}\"))\n",
    "\n",
    "# tmax\n",
    "#\n",
    "logging.info(f\"Calculating tmax1day for {IN_DATASET}...\")\n",
    "tmax1day = ds_working.tmax.resample(time=\"YE\").max(dim=[\"time\"])\n",
    "tmax1day_F = units.convert_units_to(tmax1day, \"degF\")\n",
    "out_file_list.append((tmax1day_F, f\"{IN_DATASET}_tmax1day_{file_suffix}\"))\n",
    "\n",
    "# TMAX days ABOVE a threshold\n",
    "#\n",
    "logging.info(f\"Calculating tmax_days_ge_85F for {IN_DATASET}...\")\n",
    "tmax_days_ge_85F = xclim.indicators.atmos.tx_days_above(tasmax=ds_working.tmax, thresh='85.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmax_days_ge_85F, f\"{IN_DATASET}_tmax-days-ge-85F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmax_days_ge_86F for {IN_DATASET}...\")\n",
    "tmax_days_ge_86F = xclim.indicators.atmos.tx_days_above(tasmax=ds_working.tmax, thresh='86.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmax_days_ge_86F, f\"{IN_DATASET}_tmax-days-ge-86F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmax_days_ge_90F for {IN_DATASET}...\")\n",
    "tmax_days_ge_90F = xclim.indicators.atmos.tx_days_above(tasmax=ds_working.tmax, thresh='90.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmax_days_ge_90F, f\"{IN_DATASET}_tmax-days-ge-90F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmax_days_ge_95F for {IN_DATASET}...\")\n",
    "tmax_days_ge_95F = xclim.indicators.atmos.tx_days_above(tasmax=ds_working.tmax, thresh='95.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmax_days_ge_95F, f\"{IN_DATASET}_tmax-days-ge-95F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmax_days_ge_100F for {IN_DATASET}...\")\n",
    "tmax_days_ge_100F = xclim.indicators.atmos.tx_days_above(tasmax=ds_working.tmax, thresh='100.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmax_days_ge_100F, f\"{IN_DATASET}_tmax-days-ge-100F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmax_days_ge_105F for {IN_DATASET}...\")\n",
    "tmax_days_ge_105F = xclim.indicators.atmos.tx_days_above(tasmax=ds_working.tmax, thresh='105.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmax_days_ge_105F, f\"{IN_DATASET}_tmax-days-ge-105F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmax_days_ge_110F for {IN_DATASET}...\")\n",
    "tmax_days_ge_110F = xclim.indicators.atmos.tx_days_above(tasmax=ds_working.tmax, thresh='110.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmax_days_ge_110F, f\"{IN_DATASET}_tmax-days-ge-110F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmax_days_ge_115F for {IN_DATASET}...\")\n",
    "tmax_days_ge_115F = xclim.indicators.atmos.tx_days_above(tasmax=ds_working.tmax, thresh='115.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmax_days_ge_115F, f\"{IN_DATASET}_tmax-days-ge-115F_{file_suffix}\"))\n",
    "\n",
    "# TMAX days BELOW a threshold\n",
    "#\n",
    "logging.info(f\"Calculating tmax_days_le_32F for {IN_DATASET}...\")\n",
    "tmax_days_le_32F = xclim.indicators.atmos.tx_days_below(tasmax=ds_working.tmax, thresh='32.0 degF', freq='YE', op='le')\n",
    "out_file_list.append((tmax_days_le_32F, f\"{IN_DATASET}_tmax-days-le-32F_{file_suffix}\"))\n",
    "\n",
    "# Summer thresholds\n",
    "#\n",
    "logging.info(f\"Calculating tmean_jja for {IN_DATASET}...\")\n",
    "tmean_jja = ds_working.tavg.sel(time=ds_working['time.season'] == 'JJA').resample(time=\"YE\").mean(dim=[\"time\"])\n",
    "tmean_jja_F = units.convert_units_to(tmean_jja, \"degF\")\n",
    "out_file_list.append((tmean_jja_F, f\"{IN_DATASET}_tmean-jja_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmin_jja for {IN_DATASET}...\")\n",
    "tmin_jja = ds_working.tmin.sel(time=ds_working['time.season'] == 'JJA').resample(time=\"YE\").min(dim=[\"time\"])\n",
    "tmin_jja_F = units.convert_units_to(tmin_jja, \"degF\")\n",
    "out_file_list.append((tmin_jja_F, f\"{IN_DATASET}_tmin-jja_{file_suffix}\"))\n",
    "\n",
    "# tmin\n",
    "#\n",
    "logging.info(f\"Calculating tmin1day for {IN_DATASET}...\")\n",
    "tmin1day = ds_working.tmin.resample(time=\"YE\").min(dim=[\"time\"])\n",
    "tmin1day_F = units.convert_units_to(tmin1day, \"degF\")\n",
    "out_file_list.append((tmin1day_F, f\"{IN_DATASET}_tmin1day_{file_suffix}\"))\n",
    "\n",
    "# TMIN days ABOVE a threshold\n",
    "#\n",
    "logging.info(f\"Calculating tmin_days_ge_60F for {IN_DATASET}...\")\n",
    "tmin_days_ge_60F = xclim.indicators.atmos.tn_days_above(tasmin=ds_working.tmin, thresh='60.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmin_days_ge_60F, f\"{IN_DATASET}_tmin-days-ge-60F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmin_days_ge_70F for {IN_DATASET}...\")\n",
    "tmin_days_ge_70F = xclim.indicators.atmos.tn_days_above(tasmin=ds_working.tmin, thresh='70.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmin_days_ge_70F, f\"{IN_DATASET}_tmin-days-ge-70F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmin_days_ge_75F for {IN_DATASET}...\")\n",
    "tmin_days_ge_75F = xclim.indicators.atmos.tn_days_above(tasmin=ds_working.tmin, thresh='75.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmin_days_ge_75F, f\"{IN_DATASET}_tmin-days-ge-75F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmin_days_ge_80F for {IN_DATASET}...\")\n",
    "tmin_days_ge_80F = xclim.indicators.atmos.tn_days_above(tasmin=ds_working.tmin, thresh='80.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmin_days_ge_80F, f\"{IN_DATASET}_tmin-days-ge-80F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmin_days_ge_85F for {IN_DATASET}...\")\n",
    "tmin_days_ge_85F = xclim.indicators.atmos.tn_days_above(tasmin=ds_working.tmin, thresh='85.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmin_days_ge_85F, f\"{IN_DATASET}_tmin-days-ge-85F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmin_days_ge_90F for {IN_DATASET}...\")\n",
    "tmin_days_ge_90F = xclim.indicators.atmos.tn_days_above(tasmin=ds_working.tmin, thresh='90.0 degF', freq='YE', op='ge')\n",
    "out_file_list.append((tmin_days_ge_90F, f\"{IN_DATASET}_tmin-days-ge-90F_{file_suffix}\"))\n",
    "\n",
    "# TMIN days BELOW a threshold\n",
    "#\n",
    "logging.info(f\"Calculating tmin_days_le_0F for {IN_DATASET}...\")\n",
    "tmin_days_le_0F = xclim.indicators.atmos.tn_days_below(tasmin=ds_working.tmin, thresh='0.0 degF', freq='YE', op='le')\n",
    "out_file_list.append((tmin_days_le_0F, f\"{IN_DATASET}_tmin-days-le-0F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmin_days_le_28F for {IN_DATASET}...\")\n",
    "tmin_days_le_28F = xclim.indicators.atmos.tn_days_below(tasmin=ds_working.tmin, thresh='28.0 degF', freq='YE', op='le')\n",
    "out_file_list.append((tmin_days_le_28F, f\"{IN_DATASET}_tmin-days-le-28F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Calculating tmin_days_le_32F for {IN_DATASET}...\")\n",
    "tmin_days_le_32F = xclim.indicators.atmos.tn_days_below(tasmin=ds_working.tmin, thresh='32.0 degF', freq='YE', op='le')\n",
    "out_file_list.append((tmin_days_le_32F, f\"{IN_DATASET}_tmin-days-le-32F_{file_suffix}\"))\n",
    "\n",
    "logging.info(f\"Threshold processing completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77533e88",
   "metadata": {},
   "source": [
    "### Write out files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over the out_file_list and write variables to netCDF\n",
    "#\n",
    "start_overall = time.perf_counter()\n",
    "logging.info(\"Begin writting files...\")\n",
    "\n",
    "for da, file_name in out_file_list:\n",
    "    out_path = os.path.join(OUT_PATH, file_name)\n",
    "    start_file = time.perf_counter()\n",
    "    da.to_netcdf(out_path)\n",
    "    end_file = time.perf_counter()\n",
    "    logging.info(f\"{da.name} saved to {out_path} in {round(end_file-start_file, 3)}\")\n",
    "\n",
    "    end_overall = time.perf_counter()\n",
    "\n",
    "logging.info(f\"Processing complete in {round(end_overall-start_overall, 3)} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
